{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization initial prediction Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id    9918441\n",
       "token_id       9918441\n",
       "class          9918441\n",
       "before         9918390\n",
       "after          9918395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "#Read train dataset CSV\n",
    "df = pd.read_csv(r'en_train.csv')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary of words which store the words that have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2006', 'IUCN', '2007', '2008', '91']\n",
      "['two thousand six', 'i u c n', 'two thousand seven', 'two thousand eight', 'ninety one']\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "dfDifference = df[df['before'] != df['after']]\n",
    "dictionary = dict(zip(dfDifference['before'],dfDifference['after']))\n",
    "print(list(islice(dictionary.keys(),5)))\n",
    "print(list(islice(dictionary.values(),5)))\n",
    "dictionary['1'] = 'one'\n",
    "dictionary['2'] = 'two'\n",
    "dictionary['3'] = 'three'\n",
    "dictionary['4'] = 'four'\n",
    "dictionary['5'] = 'five'\n",
    "dictionary['6'] = 'six'\n",
    "dictionary['7'] = 'seven'\n",
    "dictionary['8'] = 'eight'\n",
    "dictionary['9'] = 'nine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the test dataset and setting the column 'y' = 1 for the words present in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_id    111810\n",
      "token_id       111810\n",
      "before         111802\n",
      "y              111810\n",
      "b              111810\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "df_test = pd.read_csv(r'en_test.csv')\n",
    "#df_test = df_test[:1000]\n",
    "df_test['y'] = 0\n",
    "df_test['b'] = 0\n",
    "for k,v in df_test.iterrows():\n",
    "    if dictionary.get(v['before']) is not None:\n",
    "        df_test.set_value(k,'y',1)\n",
    "eg = df_test[df_test['y'] == 1]\n",
    "print(eg.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning a unique number for the words in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_col = df_test['before'].unique()\n",
    "\n",
    "before_list = dict(zip(unique_col, range(1,np.count_nonzero(unique_col)))) \n",
    "\n",
    "for k,v in df_test.iterrows():\n",
    "    if before_list.get(v['before']) is not None:\n",
    "        num = before_list[v['before']]\n",
    "        df_test.set_value(k,'b',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.330871\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>   <td>1088564</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>1088562</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Dec 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.0004020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:08:02</td>     <th>  Log-Likelihood:    </th> <td>-3.6017e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-3.6032e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>5.765e-65</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td> 2.239e-06</td> <td> 1.29e-07</td> <td>   17.320</td> <td> 0.000</td> <td> 1.99e-06</td> <td> 2.49e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.1937</td> <td>    0.004</td> <td> -621.068</td> <td> 0.000</td> <td>   -2.201</td> <td>   -2.187</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:              1088564\n",
       "Model:                          Logit   Df Residuals:                  1088562\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sat, 16 Dec 2017   Pseudo R-squ.:               0.0004020\n",
       "Time:                        00:08:02   Log-Likelihood:            -3.6017e+05\n",
       "converged:                       True   LL-Null:                   -3.6032e+05\n",
       "                                        LLR p-value:                 5.765e-65\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "b           2.239e-06   1.29e-07     17.320      0.000    1.99e-06    2.49e-06\n",
       "intercept     -2.1937      0.004   -621.068      0.000      -2.201      -2.187\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "df_test['intercept'] = 1.0\n",
    "word_prediction = sm.Logit(df_test['y'], df_test[['b','intercept']]).fit()\n",
    "word_prediction.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897442869689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "lr = LogisticRegression(C=1e9)\n",
    "\n",
    "X = df_test['b']\n",
    "X = X.reshape(-1, 1)\n",
    "y = df_test['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "LRm = logreg.fit(X_train, y_train)\n",
    "a=metrics.accuracy_score(y_train, LRm.predict(X_test))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897130531599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "#print(y_train.count())\n",
    "y_pred_class = mnb.predict(df_test['b'][:544282].reshape(-1,1))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 1, 'c': 1}\n",
      "[[  202]\n",
      " [ 3266]\n",
      " [11033]\n",
      " ..., \n",
      " [   26]\n",
      " [   51]\n",
      " [   15]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "train = [(dict(a=1,b=1,c=1), 'y'),(dict(a=1,b=1,c=1), 'x'),(dict(a=1,b=1,c=0), 'y'),(dict(a=0,b=1,c=1), 'x'),(dict(a=0,b=1,c=1), 'y'),(dict(a=0,b=0,c=1), 'y'),(dict(a=0,b=1,c=0), 'x'),\n",
    "(dict(a=0,b=0,c=0), 'x'),\n",
    "(dict(a=0,b=1,c=1), 'y')]\n",
    "train_set = [(1,'y'),(2,'x')]\n",
    "print(dict(a=1,b=1,c=1))\n",
    "print(X_train[5:])\n",
    "#print(dict(X_train[5:].tolist()))\n",
    "#classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
